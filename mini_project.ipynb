{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*A:* In the covariance equation from the numerator we learn the direction of related changes of the variables for it sums the dot products of the difference of every sample from each dataset from it's mean. For example as one variable increases and the other one decreases most of the products that will be summed up will be negative and as a result we'll get a negative covariance. Because the magnitude of the covariance depends on the specific data set and the magnitude of the values in the sample it can't give us a unified measure for all data sets to measure how much the variables are \"changing together\". This correction comes with the correlation equation where the denominator standartizes the values of the dataset and thus gives us a unified measure for all possible data sets not only for the direction of mutual change but also it's magnitude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add the equations of cov and corr here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*B:* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "import seaborn as sns\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal.length  sepal.width  petal.length  petal.width variety\n",
      "0           5.1          3.5           1.4          0.2  Setosa\n",
      "1           4.9          3.0           1.4          0.2  Setosa\n",
      "2           4.7          3.2           1.3          0.2  Setosa\n",
      "3           4.6          3.1           1.5          0.2  Setosa\n",
      "4           5.0          3.6           1.4          0.2  Setosa\n"
     ]
    }
   ],
   "source": [
    "Iris_df = pd.read_csv(\"iris.csv\")\n",
    "print(Iris_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add visualization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*C:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Iris_df_numbers = Iris_df.select_dtypes(include=['number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcCov(x, y):\n",
    "  x = x.to_numpy()\n",
    "  y = y.to_numpy()\n",
    "  x_normalized = np.apply_along_axis(lambda x: x - np.mean(x), 0, x)\n",
    "  y_normalized = np.apply_along_axis(lambda y: y - np.mean(y), 0, y)\n",
    "  return np.dot(x_normalized.T, y_normalized) / (x.shape[0]-1) # for a covariance from a sample and not population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covMat(data):\n",
    "  cov_mat = np.zeros((data.shape[1], data.shape[1]))\n",
    "  for i in range(data.shape[1]):\n",
    "    for j in range(data.shape[1]):\n",
    "      cov_mat[i, j] = calcCov(data.iloc[:, i], data.iloc[:, j])\n",
    "  return cov_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*D: test 1*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.68569351 -0.042434    1.27431544  0.51627069]\n",
      " [-0.042434    0.18997942 -0.32965638 -0.12163937]\n",
      " [ 1.27431544 -0.32965638  3.11627785  1.2956094 ]\n",
      " [ 0.51627069 -0.12163937  1.2956094   0.58100626]]\n",
      "[[ 0.68569351 -0.042434    1.27431544  0.51627069]\n",
      " [-0.042434    0.18997942 -0.32965638 -0.12163937]\n",
      " [ 1.27431544 -0.32965638  3.11627785  1.2956094 ]\n",
      " [ 0.51627069 -0.12163937  1.2956094   0.58100626]]\n"
     ]
    }
   ],
   "source": [
    "print(covMat(Iris_df_numbers))\n",
    "print(np.cov(Iris_df_numbers, rowvar=False)) # rowvar = False, cause in our dataframe each column represents a variable and not the rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*E:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrMat(data):\n",
    "  cov_mat = covMat(data)\n",
    "  denomenator = np.zeros((data.shape[1], data.shape[1]))\n",
    "  corr_mat = np.zeros((data.shape[1], data.shape[1]))\n",
    "  for i in range(data.shape[1]):\n",
    "    for j in range(data.shape[1]):\n",
    "      denomenator[i,j] = np.sqrt(data.iloc[:, i].var() * data.iloc[:, j].var())\n",
    "      corr_mat[i,j] = cov_mat[i,j] / denomenator[i,j]\n",
    "  return corr_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.         -0.11756978  0.87175378  0.81794113]\n",
      " [-0.11756978  1.         -0.4284401  -0.36612593]\n",
      " [ 0.87175378 -0.4284401   1.          0.96286543]\n",
      " [ 0.81794113 -0.36612593  0.96286543  1.        ]]\n",
      "[[ 1.         -0.11756978  0.87175378  0.81794113]\n",
      " [-0.11756978  1.         -0.4284401  -0.36612593]\n",
      " [ 0.87175378 -0.4284401   1.          0.96286543]\n",
      " [ 0.81794113 -0.36612593  0.96286543  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(corrMat(Iris_df_numbers))\n",
    "print(np.corrcoef(Iris_df_numbers, rowvar=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G. add heatmaps to the code "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Company      Product   TypeName  Inches                    ScreenResolution  \\\n",
      "0   Apple  MacBook Pro  Ultrabook    13.3  IPS Panel Retina Display 2560x1600   \n",
      "1   Apple  Macbook Air  Ultrabook    13.3                            1440x900   \n",
      "2      HP       250 G6   Notebook    15.6                   Full HD 1920x1080   \n",
      "3   Apple  MacBook Pro  Ultrabook    15.4  IPS Panel Retina Display 2880x1800   \n",
      "4   Apple  MacBook Pro  Ultrabook    13.3  IPS Panel Retina Display 2560x1600   \n",
      "\n",
      "  CPU_Company       CPU_Type  CPU_Frequency (GHz)  RAM (GB)  \\\n",
      "0       Intel        Core i5                  2.3         8   \n",
      "1       Intel        Core i5                  1.8         8   \n",
      "2       Intel  Core i5 7200U                  2.5         8   \n",
      "3       Intel        Core i7                  2.7        16   \n",
      "4       Intel        Core i5                  3.1         8   \n",
      "\n",
      "                Memory GPU_Company                GPU_Type  OpSys  \\\n",
      "0            128GB SSD       Intel  Iris Plus Graphics 640  macOS   \n",
      "1  128GB Flash Storage       Intel        HD Graphics 6000  macOS   \n",
      "2            256GB SSD       Intel         HD Graphics 620  No OS   \n",
      "3            512GB SSD         AMD          Radeon Pro 455  macOS   \n",
      "4            256GB SSD       Intel  Iris Plus Graphics 650  macOS   \n",
      "\n",
      "   Weight (kg)  Price (Euro)  \n",
      "0         1.37       1339.69  \n",
      "1         1.34        898.94  \n",
      "2         1.86        575.00  \n",
      "3         1.83       2537.45  \n",
      "4         1.37       1803.60  \n"
     ]
    }
   ],
   "source": [
    "laptop_price_df = pd.read_csv(\"laptop_price - dataset.csv\")\n",
    "print(laptop_price_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 13))\n",
    "sns.boxplot(laptop_price_df, x='Company', y='Price (Euro)', hue=\"Company\")\n",
    "plt.title(\"Distribution and Variation of Laptop Prices Across Companies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laptop_mean_price_df = laptop_price_df[['Price (Euro)','Company']].groupby('Company').mean() #need to chane the title to mean price\n",
    "laptop_mean_price_df.rename(columns={'Price (Euro)':'Mean Laptop Price (Euro)'}, inplace=True)\n",
    "laptop_mean_price_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laptop_price_company = laptop_price_df[['Price (Euro)','Company']]\n",
    "laptop_price_company_max = laptop_price_company[laptop_price_company['Price (Euro)']==laptop_price_company.groupby('Company').max().max()['Price (Euro)']]\n",
    "laptop_price_company_max.rename(columns={'Price (Euro)':'Max Laptop Price (Euro)'}, inplace=True)\n",
    "laptop_price_company_max"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
